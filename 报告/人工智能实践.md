# 人工智能实践

### Facebook机器阅读理解系统DrQA分析

* 李佳政
* 计算技术研究所
* 201828013229075

#### 参考文献
Danqi Chen, et al.Reading Wikipedia to Answer Open-Domain Questions
https://arxiv.org/abs/1704.00051

## 一、介绍

机器阅读理解(Machine Reading Comprehension)的热度自2016年斯坦福发布SQuAD后就高居不下，随后微软也发布了来自Bing搜索日志的数据集MARCO。2018年初，百度也开放了首个中文数据集，其中文档来自于百度知道和百度搜索的网页内容。SQuAD2.0则重点关注那些找不到答案的问题。
阅读理解的任务与我们平时做的英语题目是一样的，阅读文章后回答一些基于这个文章的问题，答案的形式可以分为完形填空(clozy-style)和总结式的一段话，这段话可以是完全来自原文，也可以使用文本生成技术来生成。更大的挑战是我们可能面对许多文档，进行多文档的问答，并且大量的文档中都不会包含我们想要的答案。这项技术也是十分实用的，在搜索引擎中，可以用来构建一些搜索提示卡片，减少用户的搜索时间，类似于基于知识图谱的问答系统，如搜索问题是“巴西的官方语言？”，我们可以提供给用户一个卡片，直接回答“葡萄牙语”，但是机器阅读理解接收的文章普遍比较长，可以获得更多的信息，可以处理一些描述类的问题，如“如何给苹果手机下载软件？”这些在百度知道社区中经常被问到的问题也是可以进行回答的。
在如今推荐系统盛行的时代，文本推荐的技术也十分完善，但是目前的文本推荐过度依赖于文本的关键词来进行搜索，而忽视了用户对于文章内容深度的要求，根本问题在于机器对于要推荐的文章理解能力不够，无法阅读真实的互联网材料来为用户进行推荐，机器阅读理解技术是解决这个问题的一种手段。
作为最早的人工智能系统，搜索引擎面临的困境与文本推荐系统相同，提出的一个简单的问题，依赖于关键词从海量的文本中检索，对于简短的问题没有明确的答案，需要人来二次阅读才能获得答案，Google提出的知识图谱是一种解决方案，这扩展了我们对于搜索的了解，例如搜索“内马尔”我们会得到内马尔的百科详细信息，搜索一个电影可能还会引申出他的导演等，都是扩展知识的一种知识途径。而机器阅读理解技术关注于不让人来二次阅读维基百科的情况下，有效率地完成这个搜索，得到正确的答案。所以我选取了机器阅读理解技术在Facebook中的应用，并对Danqi Chen发表的论文进行解读，并且我的毕业设计也是机器阅读理解技术相关。

## 二、DrQA系统

搜索引擎的问答系统与智能客服问答系统最大的区别就是，开放领域的问答与特定领域的问答，难度也是不同的。但总的来说都是分为两步，第一步是检索(Document Retriever)，从大规模文档中找到与Query相似的文档，常用的方法有minHash或者神经网络的方法，典型的文档检索问题。第二步阅读理解(Document Reader)，就是用各种算法，从文档中抽取出我们要的问题答案。有时还会有额外的后处理，如多个候选文档中选出最好的答案，语言模型来平滑生成的答案。

DrQA的检索系统主要利用2-gram的语言模型哈希和TF-IDF来进行文档检索，使用的语料就是维基百科，对于中文的数据，可以使用一些开放的基础问答社区或者百度百科。答案检测模块使用一个多层的循环神经网络。Facebook在做系统方面一向很有作为，在科研领域，提出过多种提高训练速度的方法，如Adaptive Softmax、Fasttext、Wav2letter语音识别系统等。在训练手段上使用远程监督来为传统数据集来扩充样本，结合了多任务学习的方法；维基百科作为唯一的知识来源，不需要预先划重点，直接文档输入即可。DrQA与IBM、微软等公司开发的问答系统相比，都取得了更好的评分结果。与知识库相比，机器阅读理解这种文本更不容易被计算机读取，难度更大。

#### 1. Document Retriever

文档检索的方法有很多，在推荐系统领域也有很多优秀的方法。Google面对大规模网页文本时，需要面临一个去重的困难，提出过minHash的算法，这种算法的效率很高，在大规模文档的情况下，召回率很高，并且效率十分高。Youtube的推荐系统曾提出一种基于embedding的过滤方法，将数百万的视频筛选为数百个量级，其中就用到了最近邻的树算法。另外的做法就是我们可以直接使用开源的检索系统，如ElasticSearch，借助他的检索能力来帮我们找到最近邻的文章。
DrQA中主要使用的方法是分别计算Query和文档的2-gram和TF-IDF向量，找到最近似的五篇文章，这种基于关键词的方法准确率不如其他方法高，但是他的效率却很高，比较适用于维基百科这种大规模索引的情况。简单的倒排索引对于这种情况来说是十分合适的，bigram模型既保证了性能也保证了内存的消耗在可以接受的范围内，为了保证不冲突，使用有符号的murmur3哈希算法把所有的bigram映射到$2^{24}$个桶内。但是这种Retriever与Reader分离的算法不利于端到端的训练。

#### 2. Document Reader

##### 文章编码

机器阅读理解模型使用的是比较常见的NLP技术，循环神经网路与注意力机制的配置。但是在特征抽取上面，使用了词向量、抽取匹配（文章中的词是否在问题中出现过，是一个二进制向量）、词特征（包括词性、命名实体识别与词频）、问题与答案的对其向量（借助注意力机制来生成分数向量）。在如今处理文本技术中，还会加入一个额外的位置嵌入(position embedding)来增强表达。

##### 问题编码

问题向量的编码比较简单，使用一个RNN，在输出层使用attention技巧。
$$
b_{j} = \frac{exp({\rm w} \cdot {\rm q}_j)} {\sum_{j'}exp({\rm w} \cdot {\rm q}_{j'}) }
$$

##### 预测

预测方式采用了效果比较好、操作方式简单的上下界预测方法，即在答案是完整地从原文中截取的，系统只需要预测最有可能包含答案的上下界即可。
最终得到两个向量，分别指示每个词作为开始和结束的概率：
$$
P_{start}(i) \propto exp({\rm p_i W_s q}) \\
P_{end}(i) \propto exp({\rm p_i W_e q})
$$
在选择词的策略上，选择从第$i$个词到第$i'$个词，满足$i \le i' \le i+15$并且$P_{start}(i) \times P_{end}(i')$最大。其中一个技巧是，由于召回的文档有五个，使用非归一化的概率可以得到概率最大的答案，根据各个文档的概率，最终输出一个预测答案。

##### 数据
1. 维基百科。作为知识来源。
2. SQuAD。斯坦福的机器阅读理解训练集。

由于是开放领域的问答系统，评估的时候选择一些开放领域的问答数据集。
1. CuratedTREC.
2. WebQuestions.
3. WikiMovies.

这些也给了我们一些启示，在评估数据的时候，需要选择一些相应的数据集来进行评价。如我们可以使用百度百科或者维基百科作为中文的数据来源，使用一些开放领域的社区问答作为评估，如百度知道等。  

#### 3. 远程监督(Distantly Supervised)

开放领域的问答系统如CuratedTREC、WebQuestions和WikiMovies只包含问题-答案对，没有相应的文档和段落作为参考，所以不能用来训练机器阅读理解系统。具体的操作就是把问题输入到Document Retriever中，召回最相关的文档，与答案不精确匹配的段落就直接扔掉了，并且只保留25-1500个词之间的段落。找到精确答案的起止位置(s和e)后，扩展20个词窗口，即向前向后20个词，如果溢出就取边界即可，根据bigram对文档排序。对于SQuAD数据集也是用同样的方法来扩充数据集。

由于这篇论文描述的系统距今已有一年半时间，而在这期间，NLP技术得到了突飞猛进的发展，如ELMo动态词向量，GPT语言模型及其增强版本GPT-2，Facebook提出的ULMFiT，Google提出的BERT模型，都将NLP的研究向前推进了很多。但是复杂的模型带来的负面影响就是计算性能的要求更大了，我们需要在性能之间进行权衡。总地来说，DrQA是一个基于机器阅读理解问答系统的优秀实现，为类似系统的开发提供了一个参考，也取得了很好的成绩。

## 三、结论

机器阅读理解发展地十分迅速，短短三年就已经在搜索引擎中得到了大规模的应用，如Google、Bing、百度等搜索引擎都已经上线了这种功能，确实为我们的生活带来了便利，简化了搜索步骤，提升了一定的智能程度。本文作为机器阅读理解兴起之时的作品，对于后续的系统开发有很大的借鉴作用，在学习过程中，我们也要不断应用新技术来改进系统。而且这种人工智能系统性的工作对于我们的知行合一有很大的帮助，计算机领域本就是注重理论与实践结合的专业。
