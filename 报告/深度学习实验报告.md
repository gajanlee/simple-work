# 深度学习实验报告

* 李佳政
* 计算技术研究所
* 201828013229075

### 实验二，车牌识别

>给定车牌的三个部分，分别训练三个数据集，分别是汉字，字母，(数字+字母)

#### 基本思路

对图像的像素点由0-255归一化到0-1的区间。随后输入到一个卷积层中，并使用最大池化，并再一次卷积层和赤化层。由于卷积层和池化层都是多维输出，随后将多维数据给平坦化，输出到一个全连接层中作为中间隐藏层，最后是输出层，作为分类概率。对于不同的任务来说，目标输出的类别不同，导致输出层维度不同以外，其它层都是一样的。

#### 具体实现

模型的实现上是比较简单的。使用Keras框架。第一个卷积层的设置如下Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), padding="same", data_format="channels_last", activation="relu")，最大池化层为MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding="same")。第二个卷计层使用Conv2D(filters=32, kernel_size=(1, 1), strides=(1, 1), padding="same", data_format="channels_last", activation="relu")，池化层MaxPooling2D(pool_size=(1, 1), strides=(1, 1), padding="same")。
由于多维度的卷积结果要输出到全连接层，可以直接使用Flatten层完成平坦化。随后通过两个全连接层Dense(512, activation="relu")和Dropout(rate=0.1)。输出层设置为类别数，激活函数使用softmax，Dense(self.num_classes, activation="softmax")。
在损失函数的选择上使用类别交叉熵损失函数，优化器使用Adam优化器，学习率设置为1e-4，用准确率来评估训练过程效果。

#### 模型summary
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_5 (Conv2D)            (None, 20, 20, 16)        160
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 10, 10, 16)        0
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 10, 10, 32)        544
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 10, 10, 32)        0
_________________________________________________________________
flatten_3 (Flatten)          (None, 3200)              0
_________________________________________________________________
dense_5 (Dense)              (None, 512)               1638912
_________________________________________________________________
dropout_3 (Dropout)          (None, 512)               0
_________________________________________________________________
dense_6 (Dense)              (None, 31)                15903
=================================================================
Total params: 1,655,519
Trainable params: 1,655,519
Non-trainable params: 0
```

#### 实验结果
```
Epoch 5/100
5370/5370 [==============================] - 3s 576us/step - loss: 0.0820 - acc: 0.9860
Epoch 6/100
5370/5370 [==============================] - 3s 545us/step - loss: 0.0606 - acc: 0.9896
Epoch 7/100
5370/5370 [==============================] - 3s 606us/step - loss: 0.0491 - acc: 0.9911
Epoch 8/100
5370/5370 [==============================] - 3s 620us/step - loss: 0.0403 - acc: 0.9931
Epoch 9/100
5370/5370 [==============================] - 3s 635us/step - loss: 0.0328 - acc: 0.9940
Epoch 10/100
5370/5370 [==============================] - 3s 567us/step - loss: 0.0275 - acc: 0.9953

test set f1_score is 0.3890493604689382
```

对于简单的字体分类任务来说，数个epoch就可以达到十分高的准确率，但随着训练的继续，虽然训练准确率很少增加，在测试集上的f1评分仍然在增加，如10epoch的评分为38.9，但是到30epoch的情况下，测试集上的结果达到了41分。可以看到，准准确率并不是一个合适的评价指标。对于这种简单的ocr识别，图像的预处理等也是比较重要的。由于汉字等比较复杂的场景还没有足够好的准确率。

### 实验三，神经网络语言模型

> 给定PTB数据集，使用LSTM训练语言模型

#### 基本思路

使用RNN对输入的序列建模，输入的数据即是基于词的序列，通过一个embedding层首先转换为稠密的向量，然后输入到LSTM中，每次LSTM计算完之后，会输出一个向量，将这个向量使用softmax层对应到词典中的ID，作为输出。在输出中的设置是每个timestep的输入对应的输出是错位的下一个词，在预处理阶段，为每个词添加开始和结束符号`<s>`与`</s>`，对不足最大长度的句子进行补齐操作。

#### 具体实现

采用Keras实现，使用一层Embedding(VOCAB_SIZE, EMBED_DIM, input_length=MAX_INPUT_LEN)作为输入的转换，然后把输入的词向量传入到LSTM中，使用参数return_sequences=True获取每个time_step的输出，对每个time_step的输出再使用全连接层进行输出，为了参数共享，我们使用TimeDistributed将Dense层包裹住。最后在计算损失函数的时候，使用了类别交叉熵来进行损失优化，并且使用准确率来进行评价语言模型的效果。

#### 实验模型summary
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 30)                0
_________________________________________________________________
embedding_1 (Embedding)      (None, 30, 45)            450090
_________________________________________________________________
lstm_1 (LSTM)                (None, 30, 50)            19200
_________________________________________________________________
time_distributed_1 (TimeDist (None, 30, 10002)         510102
=================================================================
Total params: 979,392
Trainable params: 979,392
Non-trainable params: 0
```

#### 实验结果
```
Epoch 1/10
500/500 [==============================] - 167s 334ms/step - loss: 4.9153 - acc: 0.4058
Epoch 2/10
500/500 [==============================] - 161s 322ms/step - loss: 3.9298 - acc: 0.4227
Epoch 3/10
500/500 [==============================] - 159s 318ms/step - loss: 3.8896 - acc: 0.4342
Epoch 4/10
500/500 [==============================] - 149s 298ms/step - loss: 3.7747 - acc: 0.4432
Epoch 5/10
500/500 [==============================] - 150s 301ms/step - loss: 3.7468 - acc: 0.4528
Epoch 6/10
500/500 [==============================] - 149s 298ms/step - loss: 3.5903 - acc: 0.4674
Epoch 7/10
500/500 [==============================] - 150s 299ms/step - loss: 3.5608 - acc: 0.4714
Epoch 8/10
500/500 [==============================] - 150s 300ms/step - loss: 3.4401 - acc: 0.4909
Epoch 9/10
500/500 [==============================] - 149s 299ms/step - loss: 3.4579 - acc: 0.4892
Epoch 10/10
500/500 [==============================] - 150s 300ms/step - loss: 3.3709 - acc: 0.5002
```

可以看到随着epoch的增加，实验的准确率是不断增加的，但是准确率始终在50左右徘徊，我认为主要原因是在LSTM中，存在冷启动的原因，例如`<s>`后的可能词语是有很多的，随着确定的单词逐渐增加，那么对应的可能单词数也在不断减少，即确定的条件概率不断增加，从而获得更高的准确率。可以看到loss是在不断下降的，但是下降的很慢，主要原因可能也是受到上述问题的影响。相比word2vec单层，LSTM对长序列的输入效果确实更好，如果能使用一些word2vec的技巧，对这个语言模型的改进应当还会有所帮助，但主流的特征抽取可能都转向了transformer，由于其良好的并行性和优越的性能。

### 实验四，文本分类

>给定一个句子，进行情感二分类。

#### 基本思路

本次实验要求使用textCNN模型，是一个基于CNN的文本分类模型，由于在之前图像实验上有过使用CNN的经验，所以实验模型的搭建是比较简单的。首先将句子的但词都转换为word embedding，将每个词向量的维度视为宽度，由于缺少channel，所以我们使用Conv1D来代替图像中的2D卷积。输入到CNN中后，我们获得了一个向量转换，随后经过多个全连接层后，经过softmax全连接层得到两个概率值，或者一个sigmoid全连接层来输出对应情感的概率。根据输出的形式不同，采用不同的target。

#### 具体实现

首先我们需要定义输入Input(shape=(MAX_LEN, ), dtype="int32")，也就是输入的句子，设定最大长度，不足的进行不全。随后我们使用Embedding(len(word_to_id), embed_mat.shape[-1], weights=[embed_mat],  input_length=MAX_LEN, trainable=False, name="embed",)来进行词向量的转换，与上个实验不同的是，我们根据给定的glove词向量，而不必重新训练词向量。然后我们把转换好的句子词向量输入到卷积网络中，Conv1D(filters=20, kernel_size=3, strides=1, padding="same", activation="relu")(input_emb)。经过全局最大池化后,
```
def reduce_max(conv):
    return tf.reduce_max(conv, reduction_indices=[1], name="gmp")
gmp = Lambda(reduce_max)(conv)
```
再输入到两个全连接网络中Dense(50, name="fc1", activation="relu")(gmp)，Dense(2, activation="softmax")(hidden)。
在损失函数上，我们依旧使用类别交叉熵损失，使用准确率来检验模型的性能。

#### 实验模型summary
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 70)                0
_________________________________________________________________
embed (Embedding)            (None, 70, 50)            2947700
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 70, 20)            3020
_________________________________________________________________
lambda_1 (Lambda)            (None, 20)                0
_________________________________________________________________
dropout_1 (Dropout)          (None, 20)                0
_________________________________________________________________
fc1 (Dense)                  (None, 50)                1050
_________________________________________________________________
dropout_2 (Dropout)          (None, 50)                0
_________________________________________________________________
dense_1 (Dense)              (None, 2)                 102
=================================================================
Total params: 2,951,872
Trainable params: 4,172
Non-trainable params: 2,947,700
```

#### 实验结果
```
Epoch 1/100
19998/19998 [==============================] - 4s 187us/step - loss: 0.6415 - acc: 0.6273 - val_loss: 0.5306 - val_acc: 0.7433
Epoch 2/100
19998/19998 [==============================] - 3s 150us/step - loss: 0.5488 - acc: 0.7264 - val_loss: 0.4874 - val_acc: 0.7727
Epoch 3/100
19998/19998 [==============================] - 3s 145us/step - loss: 0.5152 - acc: 0.7476 - val_loss: 0.4781 - val_acc: 0.7753
Epoch 4/100
19998/19998 [==============================] - 3s 148us/step - loss: 0.4912 - acc: 0.7627 - val_loss: 0.4472 - val_acc: 0.7948
Epoch 5/100
19998/19998 [==============================] - 3s 145us/step - loss: 0.4765 - acc: 0.7746 - val_loss: 0.4317 - val_acc: 0.8066

... ...

Epoch 96/100
19998/19998 [==============================] - 4s 179us/step - loss: 0.3578 - acc: 0.8413 - val_loss: 0.2944 - val_acc: 0.8829
Epoch 97/100
19998/19998 [==============================] - 3s 174us/step - loss: 0.3609 - acc: 0.8374 - val_loss: 0.3099 - val_acc: 0.8722
Epoch 98/100
19998/19998 [==============================] - 4s 183us/step - loss: 0.3524 - acc: 0.8440 - val_loss: 0.2944 - val_acc: 0.8805
Epoch 99/100
19998/19998 [==============================] - 3s 169us/step - loss: 0.3614 - acc: 0.8381 - val_loss: 0.2959 - val_acc: 0.8809
Epoch 100/100
19998/19998 [==============================] - 4s 176us/step - loss: 0.3573 - acc: 0.8410 - val_loss: 0.2930 - val_acc: 0.8792
```

可以看出，随着训练epoch的不断增加，验证集的损失在不断下降，准确率从74提升到到88，可以看出并没有到达过拟合的epoch次数，只是受限于模型的能力。由于CNN没有对时序数据的处理能力，所以对词语组合上没有太好的预测效果。


### 实验五，猫狗分类

>使用迁移学习方法，进行分类，而不是重新训练全部网络权重
