# 自然语言处理项目报告

* 李佳政
* 201828013229075
* 计算技术研究所

### 选题概况

中文英文姓名翻译。基本思路是找到一个中英文对照的数据集，然后根据端到端的训练。

### 数据准备

数据来自于这个网站，爬取了部分名字，http://www.resgain.net/english_names_a.html。

#### 关于数据预处理

* 数据示例
```
Angie 安吉
Ann 安
Anna 安娜
Anne 安
Annette 安妮特
Annie 安妮
```
* 不进行分词，直接输入，输入与输出共用词表
```
<s> a n g i e </s>
<s> 安 吉 </s>
```

### 模型架构

使用BiLSTM+Attention的端到端模型。

### 代码

* 采用pyTorch框架
* encoder-decoder模式的代码

#### 1. Encoder

* 定义forward方法
```python
def forward(self, input_sequence, input_lengths, hidden=None):
    embedded = self.embedding(input_sequence)
    # 打包padding
    packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)
    outputs, hidden = self.gru(packed, hidden)
    # 解包
    outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)

    # bidirectional 求和
    outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]
    return outputs, hidden
```
编码层包括一个embedding获取字符向量，一个biRNN层用来编码输入层，求和后作为输出。

#### 2. 注意力层

* 定义三种Attention
```python
# 点乘方法
torch.sum(hidden*encoder_output, dim=2)

# 一般的注意力方法
self.attn = nn.Linear(self.hidden_size, hidden_size)
energy = self.attn(encoder_output)
torch.sum(hidden*energy, dim=2)

# 级联注意力
self.attn = nn.Linear(self.hidden_size*2, hidden_size)
self.v = nn.Parameter(torch.FloatTensor(hidden_size))
energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()
torch.sum(hidden*energy, dim=2)
```

#### 3. Decoder

* 训练时decoder，输入包含标准答案
```python
def forward(self, input_step, last_hidden, encoder_outputs):
    embedded = self.embedding(input_step)
    embedded = self.embedding_dropout(embedded)

    rnn_output, hidden = self.gru(embedded, last_hidden)
    attn_weights = self.attn(rnn_output, encoder_outputs)
    
    context = attn_weights.bmm(encoder_outputs.transpose(0, 1))

    rnn_output = rnn_output.squeeze(0)
    context = context.squeeze(1)
    concat_input = torch.cat((rnn_output, context), 1)
    concat_output = torch.tanh(self.concat(concat_input))

    output = self.out(concat_output)
    output = F.softmax(output, dim=1)
    return output, hidden
```

* 评估时的decoder，不包含正确答案，每次都选择上一次的概率最大的k个结果作为输入
```python
def forward(self, input_seq, input_length, max_length):
    encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)
    
    decoder_hidden = encoder_hidden[:self.decoder.n_layers]
    decoder_input = torch.ones(1, 1, dtype=torch.long)#, device=device, dtype=torch.long)

    all_tokens = torch.zeros([0], dtype=torch.long)#, device=device, dtype=torch.long)
    all_scores = torch.zeros([0])#, device=device)

    for _ in range(max_length):
        decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)
        # torch.max? as next decoder input
        decoder_scores, decoder_input = torch.max(decoder_output, dim=1)

        all_tokens = torch.cat((all_tokens, decoder_input), dim=0)
        all_scores = torch.cat((all_scores, decoder_scores), dim=0)

        decoder_input = torch.unsqueeze(decoder_input, 0)

    return all_tokens, all_scores
```

#### 4. 损失函数
```python
def maskNLLLoss(input, target, mask):
    nTotal = mask.sum()
    crossEntropy = -torch.log(torch.gather(input, 1, target.view(-1, 1)).squeeze(1))
    loss = crossEntropy.masked_select(mask).mean()
    loss = loss#.to(device)
    return loss, nTotal.item()
```

#### 实验结果

loss不断下降，代码实现正确
```
Iteration: 10; Percent complete: 0.0%; Average loss: 5.8140
Iteration: 20; Percent complete: 0.1%; Average loss: 5.7949
...
Iteration: 6710; Percent complete: 16.8%; Average loss: 2.8032
Iteration: 6720; Percent complete: 16.8%; Average loss: 2.7672
Iteration: 6730; Percent complete: 16.8%; Average loss: 2.7904
...
Iteration: 39750; Percent complete: 99.4%; Average loss: 1.1149
Iteration: 39860; Percent complete: 99.7%; Average loss: 1.1935
Iteration: 40000; Percent complete: 100.0%; Average loss: 1.1524
```

### 实验评价

由于音译的情况，所以很难评断翻译的质量，所以选取部分英文名字进行翻译后，通过人来观察翻译结果。

挑选多个英文名字在不同阶段的翻译进行评价
* 实验开始阶段
```
abie => ['密', '密', '富', '昂', '昂', 'k', 'k']
mike => ['密', '缇', '麦', 'k', '富', '富', 'k']
root => ['密', '密', '缇', '密', '缇', '麦', '密']
taylor => ['密', '密', '歇', '顿', '沽', '依', '密']
brook => ['密', '密', '歇', '步', '步', '顿', '沽']
brooke => ['密', '密', '缇', '密', '缇', '麦', '密']
```
随机初始化向量，所以显示出随机预测的特性，迭代60步左右翻译结果不再有英文字母。

* 模式调节阶段
```
abie => ['EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS']
mike => ['EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS']
root => ['EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS']
taylor => ['EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS']
brook => ['EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS']
brooke => ['EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS', 'EOS']
```
大约200步左右，预测的结果全为SOS、EOS这种模式类的填充。
在几千步之后，终于学习完毕SOS开头，EOS结尾的模式，并开始进行翻译权重调节。

* 翻译阶段
```
abie => ['SOS', 'SOS', 'SOS', '罗', '斯', 'EOS', 'EOS']
mike => ['SOS', 'SOS', 'SOS', '罗', 'EOS', 'EOS', 'EOS']
root => ['SOS', '阿', '斯', '斯', 'EOS', 'EOS', 'EOS']
taylor => ['SOS', '伊', '斯', '斯', 'EOS', 'EOS', 'EOS']
brook => ['SOS', '伊', '斯', '斯', 'EOS', 'EOS', 'EOS']
brooke => ['SOS', '伊', '斯', '斯', 'EOS', 'EOS', 'EOS']
```
逐渐开始翻译中文，但是准确性不是很好，基本模式SOS、EOS是正确的。

* 细化阶段
```
abie => ['SOS', '凯', '莉', 'EOS', 'EOS', 'EOS', 'EOS']
mike => ['SOS', '杰', '克', 'EOS', 'EOS', 'EOS', 'EOS']
root => ['SOS', '罗', '莉', '特', 'EOS', 'EOS', 'EOS']
taylor => ['SOS', '艾', '托', 'EOS', 'EOS', 'EOS', 'EOS']
brook => ['SOS', '罗', '罗', '克', 'EOS', 'EOS', 'EOS']
brooke => ['SOS', '罗', '罗', '克', 'EOS', 'EOS', 'EOS']
```
大体上是对的，但由于数据量过少，单词内部的组合描述不是很多，所以导致测试阶段效果不理想，但是部分音节都是正确的。

* 过拟合阶段
```
abie => ['SOS', '凯', '蒂', 'EOS', 'EOS', 'EOS', 'EOS']
mike => ['SOS', '杰', '克', 'EOS', 'EOS', 'EOS', 'EOS']
root => ['SOS', '罗', '伯', '特', 'EOS', 'EOS', 'EOS']
taylor => ['SOS', '艾', '莉', 'EOS', 'EOS', 'EOS', 'EOS']
brook => ['SOS', '罗', '罗', '克', 'EOS', 'EOS', 'EOS']
brooke => ['SOS', '罗', '罗', '尼', 'EOS', 'EOS', 'EOS']
```
在训练三万次后，模式逐渐与训练集过拟合，即依靠输入的部分模式预测整体的翻译结果。

* 其他模式评估
```
mike to ['SOS', '杰', '安', 'EOS', 'EOS', 'EOS', 'EOS']
axel to ['SOS', '伊', '劳', '丽', '娅', 'EOS', 'EOS']
aviva to ['SOS', '艾', '莉', '亚', 'EOS', 'EOS', 'EOS']
avi to ['SOS', '莉', '莉', 'EOS', 'EOS', 'EOS', 'EOS']
qiana to ['SOS', '莉', '娜', 'EOS', 'EOS', 'EOS', 'EOS']
quaid to ['SOS', '罗', '蒂', 'EOS', 'EOS', 'EOS', 'EOS']
lacy to ['SOS', '凯', '安', 'EOS', 'EOS', 'EOS', 'EOS']
lael to ['SOS', '莉', '尔', 'EOS', 'EOS', 'EOS', 'EOS']
laddle to ['SOS', '阿', '尔', '兰', '尔', 'EOS', 'EOS']
```
总体来说预测结果还是可以接受的，部分音节的预测已经能够识别，但是对应关系不是很好。

### 实验分析

首先考虑数据集的规模，约八百条的数据，所以数据集的规模还是比较小的，并且模型需要的参数量也比较大，所以很容易欠拟合，在实际的预测中需要持续训练很多步才能得到相对正确的结果。
使用序列模型的优点是不需要做特征，但是由于音译的情况是有音节匹配的情况的，但是由于数据限制无法找到分割点，所以尝试使用中文的拼音作为输入，但是效果也不是很好，并且汉字对应也会有一些信息丢失的问题。
我认为音节的对应是很重要的一环，一个有想法但是没有尝试的方案是使用规则统计英文的1/2/3-gram字母对，和中文拼音进行比较计算相似度，根据拼音回馈对应到。

这次实验让我体会到了自然语言处理任务的艰巨，但是相比较图像处理等领域，可写规则与可解释性是更强的，对于实验的反馈过程也比较明显。但是神经网络模型会弱化这种可解释性，在发生badcase的情况下，无法很好地通过修改模型来改进效果。
